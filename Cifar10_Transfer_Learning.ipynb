{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a2FPIoActAp"
      },
      "source": [
        "#importing the necessary dependencies\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, BatchNormalization,Activation\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVFM43ocvOKn",
        "outputId": "a2ba460e-8c3e-4775-e6bb-221aef6bf65c"
      },
      "source": [
        "#loading dataset from keras module\n",
        "(X_train, y_train),(X_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "c8ZThjlvvqqR",
        "outputId": "060ecfea-dfb1-45b0-f5c5-c8d2654b6ab0"
      },
      "source": [
        "#plotting some images from the dataset\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.imshow(X_train[7])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoMi39hbwwq9"
      },
      "source": [
        "#convert the pixel values of the dataset to float type \n",
        "X_train=X_train.astype('float32')\n",
        "y_train=y_train.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "X_train=X_train/255.0\n",
        "X_train=X_train/255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnFL6fEty1Fl",
        "outputId": "b003fd15-407b-4f68-9efe-3e31b8f82a8d"
      },
      "source": [
        "#perform one-hot encoding for target classes\n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes=y_train.shape[1]\n",
        "num_classes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R8dZGACSSvh"
      },
      "source": [
        "The 10 different classes of this dataset are:\n",
        "1) Airplane\n",
        "2) Car\n",
        "3) Bird\n",
        "4) Cat\n",
        "5) Deer\n",
        "6) Dog\n",
        "7) Frog\n",
        "8) Horse\n",
        "9) Ship\n",
        "10) Truck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOUPpcjoRfj_"
      },
      "source": [
        "#Create the Sequential model and add the layers\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), input_shape=(32,32,3),  kernel_initializer='he_uniform', padding='same', activation='relu'))  #filters=32, kernel_size=3,3\n",
        "model.add(Dropout(0.2))       \n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu' ))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i10TSZWUVFMW"
      },
      "source": [
        "#compile the m odel\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7wU5gZ5XNSJ",
        "outputId": "273d0906-d412-4f4a-8a6c-dc9cadff0c83"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyliGSIxXSCH",
        "outputId": "6e4a95af-6bd1-47a7-879a-9651213bde9d"
      },
      "source": [
        "#fit the model on train data\n",
        "model.fit(X_train,y_train,batch_size=32, epochs=10, verbose=1,validation_data=(X_test,y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 41s 5ms/step - loss: 2.0477 - accuracy: 0.2509 - val_loss: 52883.5469 - val_accuracy: 0.2775\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6849 - accuracy: 0.4040 - val_loss: 52938.8828 - val_accuracy: 0.2799\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5631 - accuracy: 0.4430 - val_loss: 52674.6094 - val_accuracy: 0.2767\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4919 - accuracy: 0.4715 - val_loss: 58216.0273 - val_accuracy: 0.2530\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4408 - accuracy: 0.4891 - val_loss: 75012.3281 - val_accuracy: 0.2167\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3930 - accuracy: 0.5082 - val_loss: 50652.8867 - val_accuracy: 0.2746\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3496 - accuracy: 0.5232 - val_loss: 63316.7930 - val_accuracy: 0.2280\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3045 - accuracy: 0.5369 - val_loss: 77964.3828 - val_accuracy: 0.2116\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2757 - accuracy: 0.5479 - val_loss: 60389.1016 - val_accuracy: 0.2380\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2418 - accuracy: 0.5581 - val_loss: 63205.1016 - val_accuracy: 0.2231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f752e321850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uJSy1A-ZW5p",
        "outputId": "213e1654-c0dd-4727-e30d-5f5260821432"
      },
      "source": [
        "ModelLoss, ModelAccuracy = model.evaluate(x_train, y_train)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1094/1094 [==============================] - 3s 3ms/step - loss: 0.8844 - accuracy: 0.6954\n",
            "Model Loss is 0.8844010829925537\n",
            "Model Accuracy is 0.6953999996185303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK2y-3jihpIw"
      },
      "source": [
        "#the model performance is not quite good, we'll try transfer learning"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYlH_UlpXyoi"
      },
      "source": [
        "model.save('cifar10_model.h5')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aVNvyFbbnGp"
      },
      "source": [
        "#Now, we'll use Transfer Learning techniques of ResNet and Vgg19\n",
        "from keras.applications import VGG19,ResNet50\n",
        "#Import the datagenerator to augment images'\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,Adam\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3It3wdCSh85r"
      },
      "source": [
        "x_train,x_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkGaSJgHjEjJ",
        "outputId": "1edc629b-6028-46ed-ee7c-fd33975b8225"
      },
      "source": [
        "#Print the dimensions of the datasets\n",
        "#Since the labels are already one-hot encoded, we have 10 classes\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((X_test.shape,y_test.shape))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMxa5sbj04p"
      },
      "source": [
        "#Data Augmentation Function:\n",
        "# Let's define an instance of the ImageDataGenerator class and set the parameters.\n",
        "#We have to instantiate for the Train,Validation and Test datasets\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip= True,\n",
        "                                    zoom_range=.1) "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07SWTJoFnWf0"
      },
      "source": [
        "#Fit the augmentation method to the data\n",
        "\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d-JkHhDrC4K",
        "outputId": "3a741aae-c4ef-4bf0-84b2-f871ed8b1cd0"
      },
      "source": [
        "#For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\n",
        "base_model_resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD2ZHRtbsfuE"
      },
      "source": [
        "The next step is to define the learning rate for the optimizer we will use. I have chosen Adam optimizer. \n",
        " Adam stands for Adaptive Moment estimation and maintains a separate learning rate for each parameter and updates them separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N-OQnO6sNqS"
      },
      "source": [
        "#defining the optimizers\n",
        "learn_rate=.001\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4EJXdA-821L"
      },
      "source": [
        "#Learning Rate Annealer: The learning rate can be modified after a set number of epochs or after a certain condition is met. \n",
        "#We will use the latter and change the learning rate if the validation error does not reduce after a set number of epochs. To do this we will use the patience parameter.'''\n",
        "\n",
        "lrr= ReduceLROnPlateau(\n",
        "                       monitor='val_accuracy', #Metric to be measured\n",
        "                       factor=.01, #Factor by which learning rate will be reduced\n",
        "                       patience=3,  #No. of epochs after which if there is no improvement in the val_accuracy, the learning rate is reduced\n",
        "                       min_lr=1e-5) #The minimum learning rate "
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQAyxb4ys7S5"
      },
      "source": [
        ""
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKA4PDu_-ABD"
      },
      "source": [
        "# Model Training. Since we're using a function to generate data, we have to use the argument fit_generator. \n",
        "#Both the train data and the validation data will be generated using the augmentation methods we have previously defined. To use the fit_generator function we will define the following parameters:\n",
        "#generator.flow(x_train,y_train,batch_size)\n",
        "\n",
        "batch_size= 100\n",
        "epochs=50\n",
        "STEPS = len(x_train) / 256\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY8sG03WslUy"
      },
      "source": [
        "#Since we have already defined Resnet50 as base_model_resnet, let us build the sequential model.\n",
        "model_2=Sequential()\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_2.add(base_model_resnet)\n",
        "model_2.add(Flatten())\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_izaniut6eq"
      },
      "source": [
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_2.add(Dense(4000,activation=('relu'),input_dim=512))\n",
        "model_2.add(Dense(2000,activation=('relu'))) \n",
        "model_2.add(Dropout(.4))#Adding a dropout layer that will randomly drop 40% of the weights\n",
        "model_2.add(Dense(1000,activation=('relu'))) \n",
        "model_2.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_2.add(Dense(500,activation=('relu')))\n",
        "model_2.add(Dropout(.2))#Adding a dropout layer that will randomly drop 20% of the weights\n",
        "model_2.add(Dense(10,activation=('softmax'))) #This is the classification layer"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSVIrSrsQzhQ",
        "outputId": "26542faa-21a4-47a8-bfd9-d919f663000a"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 4000)              8196000   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2000)              8002000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1000)              2001000   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 42,292,222\n",
            "Trainable params: 42,239,102\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAw-Uoa3Q4hw"
      },
      "source": [
        "model_2.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxbRlxvyR0HR",
        "outputId": "b21ba4ba-2853-4be1-c0fd-6e44ca410445"
      },
      "source": [
        "model_2.fit_generator(train_generator.flow(x_train,y_train,batch_size=256),\n",
        "                     epochs=100,steps_per_epoch=STEPS,\n",
        "                     validation_data=val_generator.flow(x_val,y_val,batch_size=256),\n",
        "                      callbacks=[lrr],verbose=1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "136/136 [==============================] - 33s 218ms/step - loss: 0.8704 - accuracy: 0.7118 - val_loss: 2.5830 - val_accuracy: 0.1043\n",
            "Epoch 2/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.7421 - accuracy: 0.7535 - val_loss: 2.5025 - val_accuracy: 0.1031\n",
            "Epoch 3/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.6744 - accuracy: 0.7788 - val_loss: 2.8221 - val_accuracy: 0.1060\n",
            "Epoch 4/100\n",
            "136/136 [==============================] - 27s 198ms/step - loss: 0.6211 - accuracy: 0.7981 - val_loss: 3.0468 - val_accuracy: 0.1061\n",
            "Epoch 5/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.5710 - accuracy: 0.8153 - val_loss: 2.3640 - val_accuracy: 0.1532\n",
            "Epoch 6/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.5436 - accuracy: 0.8269 - val_loss: 3.9408 - val_accuracy: 0.1487\n",
            "Epoch 7/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.5030 - accuracy: 0.8373 - val_loss: 4.7606 - val_accuracy: 0.1058\n",
            "Epoch 8/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.4678 - accuracy: 0.8495 - val_loss: 3.5027 - val_accuracy: 0.1104\n",
            "Epoch 9/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.3851 - accuracy: 0.8753 - val_loss: 1.5491 - val_accuracy: 0.5383\n",
            "Epoch 10/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.3582 - accuracy: 0.8849 - val_loss: 0.8101 - val_accuracy: 0.7501\n",
            "Epoch 11/100\n",
            "136/136 [==============================] - 27s 198ms/step - loss: 0.3402 - accuracy: 0.8889 - val_loss: 0.6305 - val_accuracy: 0.8019\n",
            "Epoch 12/100\n",
            "136/136 [==============================] - 27s 199ms/step - loss: 0.3264 - accuracy: 0.8944 - val_loss: 0.6030 - val_accuracy: 0.8127\n",
            "Epoch 13/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.3190 - accuracy: 0.8988 - val_loss: 0.5933 - val_accuracy: 0.8109\n",
            "Epoch 14/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.3085 - accuracy: 0.8980 - val_loss: 0.6002 - val_accuracy: 0.8112\n",
            "Epoch 15/100\n",
            "136/136 [==============================] - 27s 198ms/step - loss: 0.3008 - accuracy: 0.9033 - val_loss: 0.6022 - val_accuracy: 0.8141\n",
            "Epoch 16/100\n",
            "136/136 [==============================] - 27s 198ms/step - loss: 0.2984 - accuracy: 0.9025 - val_loss: 0.5942 - val_accuracy: 0.8198\n",
            "Epoch 17/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2967 - accuracy: 0.9025 - val_loss: 0.6041 - val_accuracy: 0.8137\n",
            "Epoch 18/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2863 - accuracy: 0.9074 - val_loss: 0.5952 - val_accuracy: 0.8183\n",
            "Epoch 19/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.2828 - accuracy: 0.9086 - val_loss: 0.5979 - val_accuracy: 0.8165\n",
            "Epoch 20/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.2810 - accuracy: 0.9086 - val_loss: 0.5876 - val_accuracy: 0.8193\n",
            "Epoch 21/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2756 - accuracy: 0.9122 - val_loss: 0.5915 - val_accuracy: 0.8200\n",
            "Epoch 22/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.2696 - accuracy: 0.9122 - val_loss: 0.5970 - val_accuracy: 0.8201\n",
            "Epoch 23/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.2640 - accuracy: 0.9129 - val_loss: 0.5920 - val_accuracy: 0.8203\n",
            "Epoch 24/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2656 - accuracy: 0.9141 - val_loss: 0.6040 - val_accuracy: 0.8164\n",
            "Epoch 25/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2608 - accuracy: 0.9144 - val_loss: 0.6050 - val_accuracy: 0.8195\n",
            "Epoch 26/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2578 - accuracy: 0.9159 - val_loss: 0.5986 - val_accuracy: 0.8226\n",
            "Epoch 27/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2484 - accuracy: 0.9191 - val_loss: 0.5998 - val_accuracy: 0.8187\n",
            "Epoch 28/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2477 - accuracy: 0.9200 - val_loss: 0.5948 - val_accuracy: 0.8241\n",
            "Epoch 29/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2471 - accuracy: 0.9190 - val_loss: 0.6025 - val_accuracy: 0.8211\n",
            "Epoch 30/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2450 - accuracy: 0.9195 - val_loss: 0.6052 - val_accuracy: 0.8224\n",
            "Epoch 31/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2424 - accuracy: 0.9221 - val_loss: 0.6068 - val_accuracy: 0.8197\n",
            "Epoch 32/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2388 - accuracy: 0.9218 - val_loss: 0.6009 - val_accuracy: 0.8231\n",
            "Epoch 33/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.2311 - accuracy: 0.9228 - val_loss: 0.6093 - val_accuracy: 0.8197\n",
            "Epoch 34/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.2307 - accuracy: 0.9241 - val_loss: 0.6277 - val_accuracy: 0.8211\n",
            "Epoch 35/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.2255 - accuracy: 0.9274 - val_loss: 0.6197 - val_accuracy: 0.8226\n",
            "Epoch 36/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.2272 - accuracy: 0.9269 - val_loss: 0.6075 - val_accuracy: 0.8234\n",
            "Epoch 37/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2270 - accuracy: 0.9260 - val_loss: 0.6044 - val_accuracy: 0.8214\n",
            "Epoch 38/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.2175 - accuracy: 0.9281 - val_loss: 0.6169 - val_accuracy: 0.8238\n",
            "Epoch 39/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2178 - accuracy: 0.9273 - val_loss: 0.6230 - val_accuracy: 0.8231\n",
            "Epoch 40/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.2198 - accuracy: 0.9277 - val_loss: 0.6256 - val_accuracy: 0.8206\n",
            "Epoch 41/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2132 - accuracy: 0.9313 - val_loss: 0.6280 - val_accuracy: 0.8225\n",
            "Epoch 42/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2118 - accuracy: 0.9313 - val_loss: 0.6157 - val_accuracy: 0.8237\n",
            "Epoch 43/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2073 - accuracy: 0.9342 - val_loss: 0.6134 - val_accuracy: 0.8249\n",
            "Epoch 44/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2052 - accuracy: 0.9342 - val_loss: 0.6352 - val_accuracy: 0.8212\n",
            "Epoch 45/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.2025 - accuracy: 0.9338 - val_loss: 0.6274 - val_accuracy: 0.8238\n",
            "Epoch 46/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.2035 - accuracy: 0.9335 - val_loss: 0.6366 - val_accuracy: 0.8214\n",
            "Epoch 47/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1960 - accuracy: 0.9371 - val_loss: 0.6421 - val_accuracy: 0.8222\n",
            "Epoch 48/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1985 - accuracy: 0.9340 - val_loss: 0.6303 - val_accuracy: 0.8225\n",
            "Epoch 49/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1947 - accuracy: 0.9373 - val_loss: 0.6337 - val_accuracy: 0.8207\n",
            "Epoch 50/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1907 - accuracy: 0.9376 - val_loss: 0.6367 - val_accuracy: 0.8217\n",
            "Epoch 51/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1886 - accuracy: 0.9373 - val_loss: 0.6348 - val_accuracy: 0.8234\n",
            "Epoch 52/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1858 - accuracy: 0.9392 - val_loss: 0.6441 - val_accuracy: 0.8224\n",
            "Epoch 53/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1831 - accuracy: 0.9402 - val_loss: 0.6503 - val_accuracy: 0.8205\n",
            "Epoch 54/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1817 - accuracy: 0.9405 - val_loss: 0.6420 - val_accuracy: 0.8239\n",
            "Epoch 55/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1800 - accuracy: 0.9413 - val_loss: 0.6535 - val_accuracy: 0.8222\n",
            "Epoch 56/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1790 - accuracy: 0.9413 - val_loss: 0.6432 - val_accuracy: 0.8221\n",
            "Epoch 57/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1737 - accuracy: 0.9432 - val_loss: 0.6586 - val_accuracy: 0.8227\n",
            "Epoch 58/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1711 - accuracy: 0.9442 - val_loss: 0.6636 - val_accuracy: 0.8238\n",
            "Epoch 59/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1679 - accuracy: 0.9463 - val_loss: 0.6743 - val_accuracy: 0.8223\n",
            "Epoch 60/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1664 - accuracy: 0.9448 - val_loss: 0.6627 - val_accuracy: 0.8236\n",
            "Epoch 61/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1646 - accuracy: 0.9462 - val_loss: 0.6673 - val_accuracy: 0.8225\n",
            "Epoch 62/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1617 - accuracy: 0.9472 - val_loss: 0.6745 - val_accuracy: 0.8229\n",
            "Epoch 63/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1634 - accuracy: 0.9464 - val_loss: 0.6878 - val_accuracy: 0.8237\n",
            "Epoch 64/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1604 - accuracy: 0.9468 - val_loss: 0.6910 - val_accuracy: 0.8204\n",
            "Epoch 65/100\n",
            "136/136 [==============================] - 27s 200ms/step - loss: 0.1576 - accuracy: 0.9479 - val_loss: 0.6764 - val_accuracy: 0.8252\n",
            "Epoch 66/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1531 - accuracy: 0.9502 - val_loss: 0.6770 - val_accuracy: 0.8245\n",
            "Epoch 67/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1537 - accuracy: 0.9503 - val_loss: 0.7227 - val_accuracy: 0.8199\n",
            "Epoch 68/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1504 - accuracy: 0.9511 - val_loss: 0.6980 - val_accuracy: 0.8215\n",
            "Epoch 69/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1459 - accuracy: 0.9526 - val_loss: 0.7180 - val_accuracy: 0.8224\n",
            "Epoch 70/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1476 - accuracy: 0.9518 - val_loss: 0.7176 - val_accuracy: 0.8179\n",
            "Epoch 71/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1486 - accuracy: 0.9513 - val_loss: 0.7104 - val_accuracy: 0.8219\n",
            "Epoch 72/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1432 - accuracy: 0.9520 - val_loss: 0.7089 - val_accuracy: 0.8217\n",
            "Epoch 73/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1433 - accuracy: 0.9535 - val_loss: 0.7036 - val_accuracy: 0.8239\n",
            "Epoch 74/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1424 - accuracy: 0.9544 - val_loss: 0.7075 - val_accuracy: 0.8252\n",
            "Epoch 75/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.1360 - accuracy: 0.9553 - val_loss: 0.7128 - val_accuracy: 0.8210\n",
            "Epoch 76/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1336 - accuracy: 0.9563 - val_loss: 0.7189 - val_accuracy: 0.8245\n",
            "Epoch 77/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1324 - accuracy: 0.9564 - val_loss: 0.7187 - val_accuracy: 0.8244\n",
            "Epoch 78/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1305 - accuracy: 0.9573 - val_loss: 0.7448 - val_accuracy: 0.8213\n",
            "Epoch 79/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1265 - accuracy: 0.9581 - val_loss: 0.7332 - val_accuracy: 0.8219\n",
            "Epoch 80/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 0.7402 - val_accuracy: 0.8218\n",
            "Epoch 81/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1250 - accuracy: 0.9588 - val_loss: 0.7511 - val_accuracy: 0.8214\n",
            "Epoch 82/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1198 - accuracy: 0.9619 - val_loss: 0.7490 - val_accuracy: 0.8225\n",
            "Epoch 83/100\n",
            "136/136 [==============================] - 27s 194ms/step - loss: 0.1178 - accuracy: 0.9619 - val_loss: 0.7690 - val_accuracy: 0.8230\n",
            "Epoch 84/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1147 - accuracy: 0.9635 - val_loss: 0.7715 - val_accuracy: 0.8230\n",
            "Epoch 85/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1188 - accuracy: 0.9616 - val_loss: 0.7680 - val_accuracy: 0.8215\n",
            "Epoch 86/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1143 - accuracy: 0.9627 - val_loss: 0.7798 - val_accuracy: 0.8184\n",
            "Epoch 87/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1114 - accuracy: 0.9639 - val_loss: 0.7693 - val_accuracy: 0.8223\n",
            "Epoch 88/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1149 - accuracy: 0.9626 - val_loss: 0.7775 - val_accuracy: 0.8209\n",
            "Epoch 89/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1072 - accuracy: 0.9661 - val_loss: 0.7796 - val_accuracy: 0.8230\n",
            "Epoch 90/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1038 - accuracy: 0.9668 - val_loss: 0.8060 - val_accuracy: 0.8196\n",
            "Epoch 91/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.8085 - val_accuracy: 0.8222\n",
            "Epoch 92/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.0986 - accuracy: 0.9697 - val_loss: 0.8227 - val_accuracy: 0.8207\n",
            "Epoch 93/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1007 - accuracy: 0.9677 - val_loss: 0.8080 - val_accuracy: 0.8245\n",
            "Epoch 94/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.0984 - accuracy: 0.9684 - val_loss: 0.8181 - val_accuracy: 0.8210\n",
            "Epoch 95/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.0957 - accuracy: 0.9692 - val_loss: 0.8345 - val_accuracy: 0.8227\n",
            "Epoch 96/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.8296 - val_accuracy: 0.8194\n",
            "Epoch 97/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.0953 - accuracy: 0.9702 - val_loss: 0.8028 - val_accuracy: 0.8221\n",
            "Epoch 98/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.0947 - accuracy: 0.9705 - val_loss: 0.8517 - val_accuracy: 0.8188\n",
            "Epoch 99/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.0875 - accuracy: 0.9721 - val_loss: 0.8671 - val_accuracy: 0.8166\n",
            "Epoch 100/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.8656 - val_accuracy: 0.8210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7489dfdcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqWj1yKvR44v"
      },
      "source": [
        "model_2.save('resnetmodel.h5')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXd84Baej4O0",
        "outputId": "c2705aee-b1f9-4ed6-a9e8-bd71a01b2d72"
      },
      "source": [
        "ModelLoss, ModelAccuracy = model_2.evaluate(x_train, y_train)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1094/1094 [==============================] - 15s 13ms/step - loss: 0.0631 - accuracy: 0.9788\n",
            "Model Loss is 0.0630747601389885\n",
            "Model Accuracy is 0.9788285493850708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkwzB1qKkf_2",
        "outputId": "a1648294-ed8d-4775-a274-d01b1d676831"
      },
      "source": [
        "ModelLoss, ModelAccuracy = model.evaluate(x_val, y_val)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 2s 3ms/step - loss: 1.0789 - accuracy: 0.6247\n",
            "Model Loss is 1.0789200067520142\n",
            "Model Accuracy is 0.624666690826416\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}